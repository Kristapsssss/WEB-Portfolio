{% include 'project_header.html' %}

<!-- portfolio section -->
<section class="section about-top" id="portfolio">
    <div class="container text-center">
        <br><br><br>
        <h1 class="section-title mb-6">Car Listings Price Prediction</h1>
    </div>

    <div class="centered-section" style="background-color: #E3DAE8; border-radius: 20px; padding: 20px;">
        <h2>Outcome</h2>
        <button class="toggle-btn" onclick="toggleIframe('visualization')">Show me the goods</button>
        <div>
            <iframe id="visualization" class="iframe-container" src="/car_prediction/" style="height: 2150px; width: 100%;"></iframe>
        </div>
    </div>

<div class="container" style="margin-top: 20px;">
    <div class="project-summary">
        <h2>Project Summary</h2>
        <p>
            <strong>Introduction:</strong> This project aims to create the most accurate model possible to predict car prices in Latvia using data from the country's most popular marketplace. The objective is to provide insights into car pricing trends based on various features.
        </p>
        <p>
            <strong>Data Collection:</strong> Data was webscraped from Latvia's leading marketplace, focusing on brands with more than 300 listings. The dataset includes attributes such as brand, model, year, engine size, mileage, and price for more than 20,000 car listings. The data was collected using Python's BeautifulSoup library.
        </p>
        <p>
            <strong>Data Cleaning:</strong> Data cleaning was performed in Google Colab using a Jupyter notebook (.ipynb file). This involved removing duplicates, handling missing values, and standardizing data formats.
        </p>
        <p>
            <strong>Technologies Used:</strong> The project utilized various technologies including Python for web scraping, data cleaning, and model development. Libraries such as Pandas, Scikit-Learn, TensorFlow, and Plotly were employed for data manipulation, machine learning, and visualization.
        </p>
        <p>
            <strong>Modeling:</strong> Multiple regression models were developed and tested to predict car prices based on the available features. These models included linear regression, random forest, gradient boosting, and neural networks. The models were evaluated based on metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R² score.
        </p>
        <p>
            <strong>Results:</strong> The best-performing model was the Gradient Boosting model, achieving the highest R² score of 0.945, indicating a strong correlation between the predicted and actual prices. The model also had a Mean Absolute Error (MAE) of 1514.69 and a Mean Squared Error (MSE) of 5662107.45. Other models performed as follows:
        </p>
        <table class="table table-bordered">
            <thead>
                <tr>
                    <th scope="col">#</th>
                    <th scope="col">Model Type</th>
                    <th scope="col">MAE</th>
                    <th scope="col">MSE</th>
                    <th scope="col">R²</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <th scope="row">1</th>
                    <td>Gradient Boosting</td>
                    <td>1514.69</td>
                    <td>5662107.45</td>
                    <td>0.945</td>
                </tr>
                <tr>
                    <th scope="row">2</th>
                    <td>XGBoost</td>
                    <td>1520.93</td>
                    <td>5723230.28</td>
                    <td>0.944</td>
                </tr>
                <tr>
                    <th scope="row">3</th>
                    <td>Neural Network</td>
                    <td>1511.52</td>
                    <td>6261612.41</td>
                    <td>0.939</td>
                </tr>
                <tr>
                    <th scope="row">4</th>
                    <td>Random Forest With Categories</td>
                    <td>1540.35</td>
                    <td>6391242.08</td>
                    <td>0.938</td>
                </tr>
                <tr>
                    <th scope="row">5</th>
                    <td>LightGBM</td>
                    <td>1552.36</td>
                    <td>6373872.90</td>
                    <td>0.938</td>
                </tr>
                <tr>
                    <th scope="row">6</th>
                    <td>K-Nearest Neighbors</td>
                    <td>1792.66</td>
                    <td>9455290.50</td>
                    <td>0.908</td>
                </tr>
                <tr>
                    <th scope="row">7</th>
                    <td>Random Forest Without Categories</td>
                    <td>2318.50</td>
                    <td>14117852.28</td>
                    <td>0.863</td>
                </tr>
                <tr>
                    <th scope="row">8</th>
                    <td>Linear Regression</td>
                    <td>3231.08</td>
                    <td>24064852.51</td>
                    <td>0.767</td>
                </tr>
                <tr>
                    <th scope="row">9</th>
                    <td>Elastic Net</td>
                    <td>3111.41</td>
                    <td>25167532.33</td>
                    <td>0.756</td>
                </tr>
                <tr>
                    <th scope="row">10</th>
                    <td>Support Vector Regression</td>
                    <td>3859.66</td>
                    <td>59155223.30</td>
                    <td>0.426</td>
                </tr>
            </tbody>
        </table>
        <p>
            These results highlight the effectiveness of different models in predicting car prices, with Gradient Boosting emerging as the most accurate.
        </p>
    </div>
</div>

    <!-- Code Snippets Section -->
    <div class="code-snippets">
        <h2>Key Code Snippets</h2>
        <div class="code-grid">
        <div class="code-item">
            <h3>Data Collection</h3>
            <pre><code class="language-python">
# Get Page Data

def get_page_data(url, brand):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")

    all_rows = soup.select('tr[id^="tr_"]')  # Select rows with id starting with "tr_"

    data = []
    for row in all_rows:
        columns = row.find_all('td')
        if len(columns) > 1:
            model = columns[3].text.strip()
            year = columns[4].text.strip()
            engine_size = columns[5].text.strip()
            mileage = columns[6].text.strip()
            price = columns[7].text.strip()
            posting = {
                'Brand': brand,
                'Model': model,
                'Year': year,
                'Engine Size': engine_size,
                'Mileage': mileage,
                'Price': price
            }
            data.append(posting)

    return data

# Loop Through All Pages for Brand

def get_all_pages_data(url, brand):
    all_data = []
    page = 1
    while True:
        page_url = f"{url}page{page}.html"
        print(f"Scraping page: {page}, the page url is: {page_url}")
        page_data = get_page_data(page_url, brand)

        # Stop if page data is empty or if it's a duplicate of the first page
        if not page_data or (page > 1 and page_data == all_data[:len(page_data)]):
            break

        all_data.extend(page_data)
        page += 1

    return all_data

# Loop Through All Brands

def scrape_all_brands(base_url, brands):
    all_brands_data = []
    for brand in brands:
        brand_url = f"{base_url}{brand.lower()}/"
        print(f"Scraping brand: {brand}, URL: {brand_url}")
        brand_data = get_all_pages_data(brand_url, brand)
        all_brands_data.extend(brand_data)
    return all_brands_data
            </code></pre>
        </div>

            <div class="code-item">
            <h3>Model Training</h3>
            <pre><code class="language-python">
# Load your data
data = pd.read_pickle('latvia_car_data.pkl')

# Filter models with more than 50 data points
model_counts = data['Model'].value_counts()
sufficient_data_models = model_counts[model_counts > 50].index
filtered_data = data[data['Model'].isin(sufficient_data_models)]

# Create new feature 'Car Age'
filtered_data['Car Age'] = 2024 - filtered_data['Year']

# Preprocess the data
filtered_data = filtered_data.dropna()
filtered_data = pd.get_dummies(filtered_data, columns=['Brand', 'Model', 'Engine Type'])  # Encoding categorical variables

# Split the data
X = filtered_data.drop('Price', axis=1)  # Features
y = filtered_data['Price']  # Target variable

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=90)

# Define the model
rf = RandomForestRegressor()

param_dist = {
    'n_estimators': randint(100, 300),
    'max_depth': randint(10, 30),
    'min_samples_split': randint(2, 15),
    'min_samples_leaf': randint(1, 10),
    'bootstrap': [True, False]
}

random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=100, cv=5,
                                   scoring='neg_mean_absolute_error', n_jobs=-1, random_state=90, verbose=2)

random_search.fit(X_train, y_train)

# Best model
best_rf = random_search.best_estimator_

# Cross-validation score
cv_score = cross_val_score(best_rf, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')
print(f'Cross-validation MAE: {-cv_score.mean()}')

# Predictions
y_pred = best_rf.predict(X_test)

# Evaluation
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'MAE: {mae}, MSE: {mse}, R²: {r2}')

            </code></pre>
        </div>

        <div class="code-item">
            <h3>Data Cleaning</h3>
            <pre><code class="language-python">
# Clean Mileage Data

df_data = df_data[df_data['Mileage'] != "-"]

def convert_mileage(mileage):
  if 'tūkst.' in mileage:
        mileage = mileage.replace(' tūkst.', '').replace(' ', '')
        return int(float(mileage) * 1000)
  else:
      mileage = mileage.replace(' ', '').replace(',', '')
      return int(mileage)

df_data['Mileage'] = df_data['Mileage'].apply(convert_mileage)
df_data.rename(columns={'Mileage': 'Mileage (km)'}, inplace=True)

# Clean Price Data and convert to integer

df_data['Price'] = df_data['Price'].str.replace(',', '').str.replace(' €', '').str.replace(' maiņai', '').astype(int)

# Convert Year to Integer

df_data['Year'] = pd.to_numeric(df_data['Year'])


            </code></pre>
        </div>

    </div>
</div>

    <!-- GitHub Button Section -->
    <div class="container text-center" style="margin-top: 20px;">
        <a href="https://github.com/Kristapsssss/Machine-Learning-Car-Price-Prediction/" class="btn btn-primary" target="_blank">View Project on GitHub</a>
    </div>

</section>

{% include 'footer.html' %}